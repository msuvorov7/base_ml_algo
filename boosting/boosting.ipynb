{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles, make_moons, load_breast_cancer, make_regression, load_diabetes, make_blobs\n",
    "from sklearn.metrics import classification_report, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Booster:\n",
    "    \n",
    "    def __init__(self, learning_rate: int, n_estimators: int):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.estimators = []\n",
    "        \n",
    "    def _fit_first_estimator(self, X, y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingRegressor(Booster):\n",
    "    \n",
    "    def __init__(self, max_depth: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.first_estimator = None\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def _fit_first_estimator(self, X, y):\n",
    "        self.first_estimator = LinearRegression()\n",
    "        self.first_estimator.fit(X, y)\n",
    "    \n",
    "    def _fit_base_estimator(self, X, y):\n",
    "        model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._fit_first_estimator(X, y)\n",
    "        \n",
    "        for i in range(1, self.n_estimators):\n",
    "            y_pred = self.first_estimator.predict(X)\n",
    "            for estimator in self.estimators:\n",
    "                y_pred += self.learning_rate * estimator.predict(X)\n",
    "            model = self._fit_base_estimator(X, self.derivate_loss(y, y_pred))\n",
    "            self.estimators.append(model)\n",
    "            \n",
    "    \n",
    "    def derivate_loss(self, y_true, y_pred):\n",
    "        'MSE loss derivate'\n",
    "        return y_true - y_pred\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.first_estimator.predict(X)\n",
    "        for estimator in self.estimators:\n",
    "            y_pred += self.learning_rate * estimator.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingClassifier(Booster):\n",
    "    \"\"\"\n",
    "    Binary classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth: int, random_state: int = 0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.first_estimator = None\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"BoostingClassifier\"\n",
    "    \n",
    "    def _fit_first_estimator(self, X, y):\n",
    "        self.first_estimator = LinearRegression()\n",
    "        self.first_estimator.fit(X, y)\n",
    "    \n",
    "    def _fit_base_estimator(self, X, y):\n",
    "        model = DecisionTreeRegressor(max_depth=self.max_depth, random_state=self.random_state)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self._fit_first_estimator(X, y)\n",
    "        \n",
    "        for i in range(1, self.n_estimators):\n",
    "            y_pred = self.first_estimator.predict(X)\n",
    "            for estimator in self.estimators:\n",
    "                y_pred += self.learning_rate * (estimator.predict(X))\n",
    "            model = self._fit_base_estimator(X, self.derivate_loss(y, y_pred))\n",
    "            self.estimators.append(model)\n",
    "            \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def derivate_loss(self, y_true, y_pred):\n",
    "        'Log loss derivate'\n",
    "        return y_true - self._sigmoid(y_pred)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_pred = self.first_estimator.predict(X)\n",
    "        for estimator in self.estimators:\n",
    "            y_pred += self.learning_rate * (estimator.predict(X))\n",
    "        return self._sigmoid(y_pred)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = self.predict_proba(X)\n",
    "        return np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingMultiClassifier(Booster):\n",
    "    \"\"\"\n",
    "    Binary multi-classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth: int, random_state: int = 0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.first_estimator = None\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"BoostingMultiClassifier\"\n",
    "    \n",
    "    def _fit_first_estimator(self, X, y):\n",
    "        self.first_estimator = LinearRegression()\n",
    "        self.first_estimator.fit(X, y)\n",
    "    \n",
    "    def _fit_base_estimator(self, X, y):\n",
    "        model = DecisionTreeRegressor(max_depth=self.max_depth, random_state=self.random_state)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        n_class = np.unique(y).shape[0]\n",
    "        y_hot = self._one_hot(y, n_class)\n",
    "        \n",
    "        self._fit_first_estimator(X, y_hot)\n",
    "        \n",
    "        for i in range(1, self.n_estimators):\n",
    "            y_pred = self.first_estimator.predict(X)\n",
    "            for estimator in self.estimators:\n",
    "                y_pred += self.learning_rate * (estimator.predict(X))\n",
    "            model = self._fit_base_estimator(X, self.derivate_loss(y_hot, y_pred))\n",
    "            self.estimators.append(model)\n",
    "            \n",
    "    def _one_hot(self, y, c):\n",
    "        y_hot = np.zeros((len(y), c))\n",
    "        y_hot[np.arange(len(y)), y] = 1\n",
    "        return y_hot\n",
    "    \n",
    "    def _softmax(self, z):\n",
    "        exp = np.exp(z - np.max(z))\n",
    "        for i in range(len(z)):\n",
    "            exp[i] /= np.sum(exp[i])\n",
    "        return exp\n",
    "    \n",
    "    def derivate_loss(self, y_true, y_pred):\n",
    "        'Log loss derivate'\n",
    "        return y_true - self._softmax(y_pred)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_pred = self.first_estimator.predict(X)\n",
    "        for estimator in self.estimators:\n",
    "            y_pred += self.learning_rate * (estimator.predict(X))\n",
    "        return self._softmax(y_pred)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = self.predict_proba(X)\n",
    "        return np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh_grid(clf_list, X, y):\n",
    "    i = 1\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16,5))\n",
    "    for clf in clf_list:\n",
    "        plt.subplot(1, 3, i)\n",
    "    \n",
    "        eps = 0.3\n",
    "\n",
    "        xx, yy = np.meshgrid(np.linspace(np.min(X[:,0]) - eps, np.max(X[:,0]) + eps, 100),\n",
    "                             np.linspace(np.min(X[:,1]) - eps, np.max(X[:,1]) + eps, 100))\n",
    "        z = clf.predict(np.c_[xx.ravel(), yy.ravel()][:, :]).reshape(xx.shape)\n",
    "\n",
    "        plt.pcolormesh(xx, yy, z, cmap='Spectral', shading='auto')\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap='Spectral', edgecolors='black')\n",
    "        plt.title(clf)\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ensemble(X, y, task):\n",
    "    \n",
    "    if task == 'clf':\n",
    "    \n",
    "        my_grad_2 = BoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "        my_grad_m = BoostingMultiClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "        sk_grad = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "        \n",
    "        my_grad_2.fit(X, y)\n",
    "        my_grad_m.fit(X, y)\n",
    "        sk_grad.fit(X, y)\n",
    "    \n",
    "        return my_grad_2, my_grad_m, sk_grad\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        my_grad = BoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "        sk_grad = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=3)\n",
    "        \n",
    "        my_grad.fit(X, y)\n",
    "        sk_grad.fit(X, y)\n",
    "    \n",
    "        return my_grad, sk_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_surface(clf, X, y, plot_step=0.2, cmap='Spectral', figsize=(10, 8)):\n",
    "    # Plot the decision boundary\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    n_classes = len(set(y))\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.5)    \n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    # Plot the training points\n",
    "    plt.scatter(*X[y_pred == y].T, marker='.', s=70,\n",
    "                c=y[y_pred == y], cmap=cmap, alpha=0.9, label='correct')\n",
    "    plt.scatter(*X[y_pred != y].T, marker='x', s=50,\n",
    "                c=y[y_pred != y], cmap=cmap, label='errors')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.axis(\"tight\")\n",
    "    plt.legend(loc='best')\n",
    "    print(\"Accuracy =\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(300, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_grad_2, my_grad_m, sk_grad = fit_ensemble(X, y, 'clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_grid([my_grad_2, my_grad_m, sk_grad], X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(300, noise=0.2, random_state=42, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_grad_2, my_grad_m, sk_grad = fit_ensemble(X, y, 'clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mesh_grid([my_grad_2, my_grad_m, sk_grad], X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer().data, load_breast_cancer().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "my_grad_2, my_grad_m, sk_grad = fit_ensemble(X_train, y_train, 'clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_grad_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_grad_m.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, sk_grad.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=300, n_features=2, cluster_std=2, centers=5, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_grad_m = BoostingMultiClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "my_grad_m.fit(X, y)\n",
    "plot_decision_surface(my_grad_m, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_grad = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "sk_grad.fit(X, y)\n",
    "plot_decision_surface(sk_grad, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return 3*np.sin(x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-3,3)\n",
    "y = F(X) + np.random.randn(len(X))\n",
    "X = X.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_grad, sk_grad = fit_ensemble(X, y, 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "t = np.arange(-3, 3, 0.05).reshape(-1,1)\n",
    "pred_my = my_grad.predict(t)\n",
    "pred_sk = sk_grad.predict(t)\n",
    "plt.plot(t, pred_my, color='orange', label='my grad', marker='s')\n",
    "plt.plot(t, pred_sk, color='green', label='sk grad')\n",
    "plt.scatter(X, y, label='sample')\n",
    "plt.plot(t, F(t), label='F(t)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes().data, load_diabetes().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "my_grad, sk_grad = fit_ensemble(X_train, y_train, 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, my_grad.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, sk_grad.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12,10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('My gradient boosting')\n",
    "plt.scatter(y_test, my_grad.predict(X_test))\n",
    "plt.xlabel('test')\n",
    "plt.ylabel('my_grad pred')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Sklearn gradient boosting')\n",
    "plt.scatter(y_test, sk_grad.predict(X_test))\n",
    "plt.xlabel('test')\n",
    "plt.ylabel('sk_grad pred')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
